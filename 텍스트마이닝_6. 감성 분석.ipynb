{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988c906f",
   "metadata": {},
   "source": [
    "# 1. 감성분석의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c5ed4",
   "metadata": {},
   "source": [
    "감성 분석 방법론은 다양하게 분류될 수 있는데, 크게는 어휘 기반의 분석과 기계학습 기반의 분석으로 나뉘어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9aeb4",
   "metadata": {},
   "source": [
    "## 1.1 어휘 기반의 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d926c67",
   "metadata": {},
   "source": [
    "어휘 기반의 감성 분석은 감성이 표현될 수 있는 명사, 형용사, 동사를 대상으로 모든 단어에 대해 긍정 혹은 부정의 감성을 붙여서 감성 사전을 구축한 후에, 이를 기반으로 텍스트에 대한 감성 분석을 수행하는 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc65cf6",
   "metadata": {},
   "source": [
    "## 1.2 머신러닝 기반의 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5997a35f",
   "metadata": {},
   "source": [
    "학습 데이터셋만 있다면 문서분류에서 사용한 다양한 알고리즘으로 학습을 통해 감성을 예측할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37960fa0",
   "metadata": {},
   "source": [
    "# 2. 감성 사전을 이용한 영화 리뷰 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c9d17",
   "metadata": {},
   "source": [
    "## 2.1 NLTK 영화 리뷰 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc06b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /data/ydkim/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#review count: 2000\n",
      "#samples of file ids: ['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n",
      "#categories of reviews: ['neg', 'pos']\n",
      "#num of \"neg\" reviews: 1000\n",
      "#num of \"pos\" reviews: 1000\n",
      "#id of the first review: neg/cv000_29416.txt\n",
      "#part of the first review: plot : two teen couples go to a church party , drink and then drive . \n",
      "they get into an accident . \n",
      "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
      "what's the deal ? \n",
      "watch the movie and \" sorta \" find out . . . \n",
      "critique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \n",
      "which is what makes this review an even harder one to write , since i generally applaud films which attempt\n",
      "#sentiment of the first review: ['neg']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "print('#review count:', len(movie_reviews.fileids())) #영화 리뷰 문서의 id를 반환\n",
    "print('#samples of file ids:', movie_reviews.fileids()[:10]) #id를 10개까지만 출력\n",
    "print('#categories of reviews:', movie_reviews.categories()) # label, 즉 긍정인지 부정인지에 대한 분류\n",
    "print('#num of \"neg\" reviews:', len(movie_reviews.fileids(categories='neg'))) #label이 부정인 문서들의 id를 반환\n",
    "print('#num of \"pos\" reviews:', len(movie_reviews.fileids(categories='pos'))) #label이 긍정인 문서들의 id를 반환\n",
    "\n",
    "fileid = movie_reviews.fileids()[0] #첫번째 문서의 id를 반환\n",
    "print('#id of the first review:', fileid)\n",
    "print('#part of the first review:', movie_reviews.raw(fileid)[:500]) #첫번째 문서의 내용을 500자까지만 출력\n",
    "print('#sentiment of the first review:', movie_reviews.categories(fileid)) #첫번째 문서의 감성\n",
    "\n",
    "fileids = movie_reviews.fileids() #movie review data에서 file id를 가져옴\n",
    "reviews = [movie_reviews.raw(fileid) for fileid in fileids] #file id를 이용해 raw text file을 가져옴\n",
    "categories = [movie_reviews.categories(fileid)[0] for fileid in fileids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd7cd49",
   "metadata": {},
   "source": [
    "## 2.2 TextBlob을 이용한 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43290466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.8/636.8 KB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /data/ydkim/.pyenv/versions/3.8.12/envs/py3.8.12/lib/python3.8/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: tqdm in /data/ydkim/.pyenv/versions/3.8.12/envs/py3.8.12/lib/python3.8/site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: click in /data/ydkim/.pyenv/versions/3.8.12/envs/py3.8.12/lib/python3.8/site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /data/ydkim/.pyenv/versions/3.8.12/envs/py3.8.12/lib/python3.8/site-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /data/ydkim/.pyenv/versions/3.8.12/envs/py3.8.12/lib/python3.8/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/data/ydkim/.pyenv/versions/3.8.12/envs/py3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e8fa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /data/ydkim/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt to /data/ydkim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /data/ydkim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /data/ydkim/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to /data/ydkim/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /data/ydkim/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc72948",
   "metadata": {},
   "source": [
    "첫째 리뷰에 대한 결과값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3168ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.06479782948532947, subjectivity=0.5188408350908352)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "result = TextBlob(reviews[0])\n",
    "print(result.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca05c5d",
   "metadata": {},
   "source": [
    "polarity는 -1과 1사이의 실수로 극성을 나타내는 반면, 우리가 가진 데이터에서는 pos와 neg로 극성을 표현하므로, 데이터에 맞게 반환하는 함수를 아래와 같이 작성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e255603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_TextBlob(docs):\n",
    "    results = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        testimonial = TextBlob(doc)\n",
    "        if testimonial.sentiment.polarity > 0:\n",
    "            results.append('pos')\n",
    "        else:\n",
    "            results.append('neg')\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e953983a",
   "metadata": {},
   "source": [
    "사이킷런에서 accuracy_score를 불러와서 아래와 같이 정확도를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0fc6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#TextBlob을 이용한 리뷰 감성분석의 정확도:  0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('#TextBlob을 이용한 리뷰 감성분석의 정확도: ', accuracy_score(categories, sentiment_TextBlob(reviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209cad90",
   "metadata": {},
   "source": [
    "생각보다 정확도가 좋지 않은 것을 볼 수 있다. 감성사전을 기반으로 하는 감성 분석의 가장 큰 문제는 이와 같이 정확도가 그리 높지 않다는 점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92dfffc",
   "metadata": {},
   "source": [
    "## 2.3 AFINN을 이용한 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c188d",
   "metadata": {},
   "source": [
    "AFINN 어휘 목록은 -5에서 5사이의 극성을 부여한 영어 단어들의 리스트다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de6b29d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting afinn\n",
      "  Downloading afinn-0.1.tar.gz (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: afinn\n",
      "  Building wheel for afinn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53448 sha256=182f3452f08743175bdac1ad835bb7448c79414f6c20fdd871c9af36426f9926\n",
      "  Stored in directory: /data/ydkim/.cache/pip/wheels/f6/6f/c3/b305c5107a17618f2938a067d5ffcbb556909d82398762089e\n",
      "Successfully built afinn\n",
      "Installing collected packages: afinn\n",
      "Successfully installed afinn-0.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/data/ydkim/.pyenv/versions/3.8.12/envs/py3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e077cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Afinn을 이용한 리뷰 감성분석의 정확도:  0.664\n"
     ]
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "def sentiment_Afinn(docs):\n",
    "    afn = Afinn(emoticons=True)\n",
    "    results = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        if afn.score(doc) > 0:\n",
    "            results.append('pos')\n",
    "        else:\n",
    "            results.append('neg')\n",
    "            \n",
    "    return results\n",
    "\n",
    "\n",
    "print('#Afinn을 이용한 리뷰 감성분석의 정확도: ', accuracy_score(categories, sentiment_Afinn(reviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba8e85",
   "metadata": {},
   "source": [
    "## 2.4 VADER를 이용한 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3b660",
   "metadata": {},
   "source": [
    "VADER는 규칙기반의 감성 분석 알고리즘을 사용하는 것으로 알려져 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40e4a63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /data/ydkim/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0790f",
   "metadata": {},
   "source": [
    "vader의 SentimentIntensityAnalyzer는 4개의 극성값을 제공한다. pos, neg, neu, compound. compound는 나머지 세 값을 적절히 조합해 -1과 1 사이의 극성값을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "947df48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Vader를 이용한 리뷰감성분석의 정확도:  0.635\n"
     ]
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def sentiment_vader(docs):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    results = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        score = analyser.polarity_scores(doc)\n",
    "        if score['compound'] > 0:\n",
    "            results.append('pos')\n",
    "        else:\n",
    "            results.append('neg')\n",
    "            \n",
    "    return results\n",
    "print('#Vader를 이용한 리뷰감성분석의 정확도: ', accuracy_score(categories, sentiment_vader(reviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78aeff",
   "metadata": {},
   "source": [
    "# 3. 학습을 통한 머신러닝 기반의 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d8ac2b",
   "metadata": {},
   "source": [
    "## 3.1 NLTK 영화 리뷰에 대한 머신러닝 기반 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ee16584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, categories, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1db64a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set dimension: (1600, 36189)\n",
      "#Test set dimension: (400, 36189)\n",
      "#Train set score: 0.998\n",
      "#Test set score: 0.797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB #sklearn이 제공하는 MultinomialNB 를 사용\n",
    "\n",
    "tfidf = TfidfVectorizer().fit(X_train) \n",
    "\n",
    "X_train_tfidf = tfidf.transform(X_train) # train set을 변환\n",
    "print('#Train set dimension:', X_train_tfidf.shape) # 실제로 몇개의 특성이 사용되었는지 확인\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
    "print('#Test set dimension:', X_test_tfidf.shape)\n",
    "\n",
    "NB_clf = MultinomialNB(alpha=0.01) # 분류기 선언\n",
    "NB_clf.fit(X_train_tfidf, y_train) #train set을 이용하여 분류기(classifier)를 학습\n",
    "print('#Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set에 대한 예측정확도를 확인\n",
    "print('#Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set에 대한 예측정확도를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e134f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
